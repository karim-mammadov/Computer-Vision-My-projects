{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXNJpJCrCGLO3HSETs2CZu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karim-mammadov/Computer-Vision-My-projects/blob/main/Animal_Faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61BEtRBgBjca"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "htz5SgcTBoji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/animal-faces"
      ],
      "metadata": {
        "id": "A_4WieTKBuR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile"
      ],
      "metadata": {
        "id": "L7l_k4j-B2Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/animal-faces.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "id": "gc0kSBl4B5tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path=\"/content/afhq\""
      ],
      "metadata": {
        "id": "gIy7MI1DB9Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "kU08KYKXCMKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/afhq/train'\n",
        "categories = os.listdir(data_dir)"
      ],
      "metadata": {
        "id": "33-NCC4ODZa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sinif pay dağılımı\n",
        "import os, pandas as pd\n",
        "\n",
        "# Fayl yollarının və etiketlərinin siyahısını yaratmaq\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(data_dir, category)\n",
        "    for filename in os.listdir(category_path):\n",
        "        filepaths.append(os.path.join(category_path, filename))\n",
        "        labels.append(category)\n",
        "\n",
        "# datanı yaratmaq\n",
        "df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
        "\n",
        "\n",
        "# Hər bir kateqoriya üçün saylarını hesablamaq\n",
        "counts = df['label'].value_counts()\n",
        "counts = counts.reindex(['cat', 'dog', 'wild']) # sifarişin indeksə uyğun olduğundan əmin olmaq\n",
        "\n",
        "counts.plot(kind='bar')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# nümunə şəbəkəsi\n",
        "fig, axes = plt.subplots(3,5, figsize=(10,6))\n",
        "for i, cls in enumerate(['cat','dog','wild']):\n",
        "    sel = df[df['label']==cls].sample(5)\n",
        "    for j, row in enumerate(sel.itertuples()):\n",
        "        img = plt.imread(row.filepath)\n",
        "        axes[i,j].imshow(img); axes[i,j].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fpf2FZAzcvk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hər kateqoriyadan bir şəkil seçmək\n",
        "for category in categories:\n",
        "    image_path = os.path.join(data_dir, category, os.listdir(os.path.join(data_dir, category))[0])\n",
        "    img = mpimg.imread(image_path)\n",
        "    plt.figure(figsize=(3, 3))\n",
        "    plt.imshow(img)\n",
        "    plt.title(category)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hU9UBAdDDcX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# img_height = 224\n",
        "# img_width = 224\n",
        "batch_size = 32\n",
        "img_size=(224,224)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_dir='/content/afhq/train'\n",
        "val_dir='/content/afhq/val'\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    seed=42,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    seed=42,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "ENqNAN0lDwWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(7,7), filters=32, strides=2, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(5,5), filters=64, strides=2, activation='relu', kernel_initializer='he_normal'),  #(7,7)\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=128, strides=2, activation='relu', kernel_initializer='he_normal'),  # 5,5\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=256, strides=2, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),  #0,5\n",
        "    tf.keras.layers.Dense(units=128, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(units=3, activation='softmax')\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "Mz8oMSSREuNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.AdamW(),  #adam\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "2zZfm6LvLg7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=len(train_ds),\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=len(val_ds)\n",
        ")"
      ],
      "metadata": {
        "id": "aKUZtYw6Lrp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vizual ilə overfitting və underfittingin olub olmadigini təyin edirik\n",
        "epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "train_acc = [0.6578, 0.8863, 0.9298, 0.9461, 0.9498, 0.9669, 0.9697, 0.9732, 0.9777, 0.9861]\n",
        "val_acc   = [0.7820, 0.8420, 0.8773, 0.9507, 0.8800, 0.9320, 0.9140, 0.9560, 0.9173, 0.9580]\n",
        "\n",
        "\n",
        "plt.plot(epochs, train_acc, label='Train Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train vs Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "le9kG4pINEsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation loss bəzən artır bu da potensial overfitting siqnalı verə bilər. Son epoch-da yaxşılaşma var (Nəticə: 0.1476).\n",
        "train_loss = [0.7809, 0.2972, 0.1907, 0.1506, 0.1368, 0.0903, 0.0868, 0.0794, 0.0612, 0.0388]\n",
        "val_loss   = [0.5576, 0.4066, 0.4127, 0.1586, 0.4399, 0.2060, 0.2836, 0.1699, 0.2911, 0.1476]\n",
        "\n",
        "plt.plot(epochs, train_loss, label='Train Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-9GzzkQeel4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YijfhH4nfYX2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}